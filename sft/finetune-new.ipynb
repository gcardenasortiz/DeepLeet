{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/deepleet/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.14: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None          # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.14 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,    # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",       # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2529.20 examples/s]\n",
      "Map: 100%|██████████| 47780/47780 [00:28<00:00, 1697.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen-2.5\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convo = examples[\"messages\"]\n",
    "    text = tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "    return { \"text\" : text }\n",
    "\n",
    "dataset = load_dataset(\"lordtachanka/leetcode_cot_fixed\", split=\"train\")\n",
    "#dataset = standardize_sharegpt(dataset)\n",
    "dataset = dataset.map(formatting_prompts_func).select_columns([\"text\"])\n",
    "\n",
    "cf_ds = load_dataset(\"open-r1/codeforces-cots\",split=\"train\")\n",
    "cf_ds = cf_ds.map(formatting_prompts_func).select_columns([\"text\"])#.shuffle(seed=42).select(range(5000))\n",
    "dataset = concatenate_datasets([dataset,cf_ds])\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nYou will be given a competitive programming problem. Please reason step by step about the solution, then provide a complete implementation in C++17.\\n\\nYour solution must read input from standard input (cin), write output to standard output (cout).\\nDo not include any debug prints or additional output.\\n\\nPut your final solution within a single code block:\\n```cpp\\n<your code here>\\n```\\n\\n# Problem\\n\\nGerald has n younger brothers and their number happens to be even. One day he bought n2 candy bags. One bag has one candy, one bag has two candies, one bag has three candies and so on. In fact, for each integer k from 1 to n2 he has exactly one bag with k candies.\\n\\nHelp him give n bags of candies to each brother so that all brothers got the same number of candies.\\n\\nExecution time limit: 1.0 seconds\\nMemory limit: 256.0 MB\\n\\n## Input Format\\nThe single line contains a single integer n (n is even, 2 ≤ n ≤ 100) — the number of Gerald\\'s brothers.\\n\\n## Output Format\\nLet\\'s assume that Gerald indexes his brothers with numbers from 1 to n. You need to print n lines, on the i-th line print n integers — the numbers of candies in the bags for the i-th brother. Naturally, all these numbers should be distinct and be within limits from 1 to n2. You can print the numbers in the lines in any order.\\n\\nIt is guaranteed that the solution exists at the given limits.\\n\\n## Examples\\n```input\\n2\\n```\\n```output\\n1 4\\n2 3\\n```\\n\\n## Note\\nThe sample shows Gerald\\'s actions if he has two brothers. In this case, his bags contain 1, 2, 3 and 4 candies. He can give the bags with 1 and 4 candies to one brother and the bags with 2 and 3 to the other brother.\\n<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, let\\'s see. The problem is to distribute n² candy bags among n brothers, each getting exactly n bags. And all brothers must have the same total number of candies. Oh right, n is even. So for example, when n is 2, the sum for each brother is (1+2+3+4)/2 = 10/2=5. Each brother gets two bags that add up to 5. The sample solution shows 1+4=5 and 2+3=5.\\n\\nHmm, I need to find a way to split the numbers from 1 to n² into n groups, each of size n, and each group\\'s sum is the same. The sum for each group should be (n²(n²+1)/2)/n) because the total sum of all candies is the sum from 1 to n², which is n²*(n²+1)/2. Then divided by n brothers, each gets (n²+1)*n²/(2n) = n(n²+1)/2. Wait, let\\'s compute that.\\n\\nSo total sum S = 1+2+...+k, where k = n². So S = k(k+1)/2. Each brother\\'s sum is S/n. Let\\'s compute for n=2: S=4*5/2=10. Each brother gets 10/2=5. Which matches the example.\\n\\nSo the key is to arrange the numbers into n groups where each group has sum S/n.\\n\\nNow, how to construct such groups. Since n is even, perhaps there\\'s a pattern here. Let\\'s think about arranging the numbers in some grid and then pairing them in a certain way.\\n\\nAnother approach: For each pair of numbers that sum up to (n² + 1), they can be grouped together. Because 1 + n² = n²+1, 2 + (n²-1) = n²+1, and so on. Since there are (n²)/2 such pairs, each pair contributes (n²+1) to the sum. Then, if each group consists of n/2 such pairs, then the total sum per group is (n/2)*(n²+1), which would be the required sum. Because (n/2)*(n²+1) = n(n²+1)/2, which is exactly the sum each brother needs. For example, in the sample n=2: each group has 2 pairs (since each group is n=2 elements, but n/2=1 pairs). So each group is a single pair. But in the sample, the first group is 1 and 4 (sum 5, which is 5=4+1=5). The second group is 2 and 3 (sum 5). So that\\'s exactly two pairs, each sum to 5. Each group is a pair, which is correct for n=2.\\n\\nSo for general even n, perhaps each brother\\'s group consists of n/2 such pairs. Then each group\\'s sum is (n/2)*(n² + 1). Which is the required sum. So the problem reduces to grouping the numbers into n groups, each containing n numbers, and each group is composed of n/2 pairs that each sum to (n² +1).\\n\\nSo the next question is: how to arrange these pairs into groups such that each group has n/2 pairs (so n numbers) and all numbers are used exactly once.\\n\\nLet me think for n=4. Then n²=16. So each group must have 4 numbers (since n=4). Each group\\'s sum is (4/2)*(16+1) = 2*17=34. So each group\\'s sum is 34. Each group has two pairs: each pair sums to 17. So for example, group 1 could have (1,16, 2,15), which sum to 1+16=17, 2+15=17, total 34. Then group 2 might have (3,14, 4,13), sum 17*2=34, and so on. But that would require grouping four pairs into two groups. Wait, n=4, each group has 4 numbers. So each group is two pairs. So for n=4, each group consists of two pairs, each summing to 17 (n²+1=16+1=17). So arranging the numbers in such a way that each group has two such pairs.\\n\\nBut how to arrange this? Let\\'s think of the numbers arranged in a grid. For example, for n=2, the pairs are (1,4) and (2,3). These are arranged as the two groups. So each group is a pair.\\n\\nBut for larger n, perhaps the numbers can be arranged in a grid where each row is a group. But how?\\n\\nAlternatively, arrange the numbers in a matrix of size n x n. Then, for each row, select certain elements such that they form pairs adding up to n²+1.\\n\\nWait, let\\'s consider the following approach. Arrange the numbers from 1 to n² in a grid. Then, for each row in this grid, arrange the elements such that each row contains pairs that sum to n²+1.\\n\\nBut how to construct such a grid.\\n\\nAlternatively, arrange the numbers in a matrix where the first row is 1, 2, ..., n. The next row is n+1, n+2, ..., 2n, etc. Then, for each row, split into pairs that sum to (n²+1). But I\\'m not sure.\\n\\nAlternatively, for each row, the elements can be arranged in such a way that for each element in the first half of the row, the corresponding element in the second half is the pair (summing to n²+1). For example, for n=2, arrange the matrix as 1,4,2,3. Then group each row into pairs. Wait, but n=2, the matrix would be 2x2. So rows would be [1,4] and [2,3], each pair summing to 5. But that\\'s exactly the sample solution. Each row is a group.\\n\\nWait, but in the sample, the output is two groups: first group is 1 and4, second 2 and3. So each group is a row in a 2x2 matrix arranged as 1,4 in first row and 2,3 in second.\\n\\nBut how to generalize this for larger n?\\n\\nAlternatively, arrange the numbers in a grid where each row contains n elements, and each row is built by selecting pairs that sum to n²+1. Then, each row can be a group for a brother.\\n\\nSo for n=4, n²=16. The sum is 16+1=17. The pairs are (1,16), (2,15), (3,14), (4,13), (5,12), (6,11), (7,10), (8,9). There are 8 pairs.\\n\\nEach group (brother) needs to have 4 elements, which is 2 pairs. So each group must have two pairs. For example, group 1 could have (1,16, 2,15) sum 17*2=34. Group 2: (3,14,4,13) sum 34, etc.\\n\\nBut arranging these into 4 groups (since n=4) each with two pairs. How to arrange them.\\n\\nAlternatively, arrange the pairs in a certain order and then distribute two pairs per group. For example, take the first two pairs for group 1, next two for group 2, etc. But that would make each group consist of two pairs. However, the order of elements in the group\\'s output can be arbitrary.\\n\\nBut perhaps there\\'s a pattern in how to arrange the pairs into groups. For example, for n=4, the first group is pairs 1 and 3, then 2 and 4? Not sure.\\n\\nAnother idea: for each group, select pairs that are arranged in a certain way. For example, in the sample, the pairs are (1,4) and (2,3). Wait, no. Wait the sample\\'s pairs are (1,4) and (2,3), but 1+4=5, 2+3=5, which sum to 5 each. So those are pairs for sum n²+1=5.\\n\\nSo perhaps, for even n, the pairs can be arranged in such a way that each group contains pairs from different positions in the original list.\\n\\nAlternatively, create a grid where each row alternates between elements from the first half and the second half. For example, for n=4, arrange the numbers in a 4x4 grid:\\n\\nRow 0: 1, 16, 2, 15\\n\\nRow 1: 3, 14, 4, 13\\n\\nRow 2: 5, 12, 6, 11\\n\\nRow 3: 7, 10, 8, 9\\n\\nThen each row has two pairs (1+16=17, 2+15=17; sum per row 34). So each row\\'s sum is 34, which is correct for n=4 (since (4*17)/2 = 34). So each row would be a group.\\n\\nBut how to generate such a grid.\\n\\nAlternatively, for the first n/2 rows, arrange the first elements in the pairs, then the next elements. For example, arrange the first n/2 rows with the first elements of pairs in order, and the next n/2 rows with the second elements.\\n\\nAlternatively, think of the pairs as (1, n²), (2, n²-1), ..., (n²/2, n²/2 +1). Then, for each group, take n/2 pairs. So each group has n elements (since each pair is two elements, and n/2 pairs per group gives 2*(n/2) =n elements per group). But how to arrange the pairs into groups such that each group has n/2 pairs.\\n\\nThe problem reduces to grouping these pairs into n groups, each containing exactly n/2 pairs. Since there are (n²)/2 pairs, each group will have (n²)/2 / n = (n/2) pairs. Which is correct.\\n\\nSo for example, n=2: there are 4/2=2 pairs. Each group is 1 pair (since n/2=1). So two groups, each with one pair. Which matches the sample.\\n\\nFor n=4: there are 16/2=8 pairs. Each group must have 8/4=2 pairs. So each group has two pairs, making 4 elements.\\n\\nSo the approach is to split the list of pairs into n groups, each group containing n/2 pairs. Then, for each group, list all elements of the pairs in any order.\\n\\nBut how to split the pairs into groups so that each group\\'s sum is correct.\\n\\nBut each pair contributes sum (n²+1), so each group\\'s sum is (n/2)*(n²+1), which is the required sum.\\n\\nSo the key is to split all the pairs into n groups, each group containing n/2 pairs.\\n\\nBut how to do that.\\n\\nAnother approach is to arrange the pairs into a grid where each row is a group. For example:\\n\\nFor n=4, the pairs are (1,16), (2,15), (3,14), (4,13), (5,12), (6,11), (7,10), (8,9).\\n\\nThese 8 pairs need to be split into 4 groups (rows), each with 2 pairs. So arrange them in the order of their numbering, and split them into chunks of 2 pairs per group.\\n\\nGroup1: (1,16), (2,15) → elements 1,16,2,15 → sum 17*2=34.\\n\\nGroup2: (3,14), (4,13) → sum 34.\\n\\nGroup3: (5,12), (6,11) → sum 34.\\n\\nGroup4: (7,10), (8,9) → sum 34.\\n\\nBut this would work, but each group\\'s elements are two pairs. So for each group, the elements are [1,16,2,15], which can be printed in any order. So the output would be lines like 1 16 2 15, etc.\\n\\nBut when you output this for n=4, the code would generate such lines.\\n\\nBut then, how to generate these pairs in code.\\n\\nSo the algorithm steps would be:\\n\\n1. Generate all pairs that sum to (n² +1). The first pair is (1, n²), second (2, n²-1), etc.\\n\\n2. Split these pairs into n groups, each containing n/2 pairs.\\n\\n3. For each group, output the elements of the pairs in any order.\\n\\nBut how to split the pairs into groups. For the sample n=2, pairs are (1,4), (2,3). Split into two groups, each with one pair. So group 1 is (1,4), group 2 is (2,3).\\n\\nFor n=4, pairs are as before. Split into groups of two pairs each, in order. So first two pairs in group 1, next two in group2, etc.\\n\\nSo in code, the pairs can be generated as a list, then split into chunks of (n/2) pairs per group.\\n\\nSo for example, for n=4, the pairs list is:\\n\\n[(1,16), (2,15), (3,14), (4,13), (5,12), (6,11), (7,10), (8,9)]\\n\\nSplit into chunks of size 2 (n/2 =4/2=2):\\n\\nChunk1: (1,16), (2,15)\\n\\nChunk2: (3,14), (4,13)\\n\\nChunk3: (5,12), (6,11)\\n\\nChunk4: (7,10), (8,9)\\n\\nEach chunk is a group. For each group, list all elements of the pairs in any order. So the first group\\'s line is 1 16 2 15 (or any permutation).\\n\\nSo the code can generate the pairs in order, split them into chunks, then for each chunk, output all the elements.\\n\\nNow, how to generate the pairs. For the i-th pair, the elements are i and (n² -i +1). So for i from 1 to (n²)/2.\\n\\nSo in code:\\n\\nvector<pair<int, int>> pairs;\\n\\nfor (int i = 1; i <= n*n / 2; ++i) {\\n    pairs.emplace_back(i, n*n - i + 1);\\n}\\n\\nThen, split these pairs into groups of (n/2) pairs each. Each group is a list of n/2 pairs.\\n\\nEach group has n/2 * 2 = n elements.\\n\\nSo for each group, we can loop through its pairs and output the first and second elements in any order. For example, first pair\\'s first element, then first pair\\'s second, then second pair\\'s first, then second pair\\'s second, etc. But the order within the group\\'s output line can be arbitrary, as long as all numbers are unique and the sum is correct.\\n\\nBut how to split the pairs into the correct number of groups. For example, the total number of pairs is (n²)/2. Each group has (n/2) pairs. So the number of groups is (n²)/2 divided by (n/2) = (n²)/(2) * 2/n ) = n. Which is correct.\\n\\nSo the code can split the pairs into groups, each of size (n/2). For example, for n=2, each group is 1 pair. For n=4, each group is 2 pairs.\\n\\nOnce the groups are formed, each group\\'s elements can be formed by taking all elements of the pairs in the group. For example, for a group with pairs (a, b) and (c, d), the elements are a, b, c, d. Or a, c, b, d, etc. The order doesn\\'t matter.\\n\\nSo the code can generate the groups as follows:\\n\\nRead n.\\n\\nCompute total pairs: m = n*n/2.\\n\\nGroup the pairs into n groups, each group has k = n/2 pairs.\\n\\nFor each group:\\n\\n   For each pair in the group:\\n\\n       output the pair\\'s first and second elements.\\n\\nBut the order in which the pairs are arranged in the group\\'s line can be any order, as long as all elements are present.\\n\\nBut how to split the pairs into groups. For example, in the sample n=2, the pairs are in order (1,4), (2,3). So groups are [pair0], [pair1].\\n\\nFor n=4, groups are [pair0, pair1], [pair2, pair3], [pair4, pair5], [pair6, pair7].\\n\\nBut this approach would create groups where each group is a consecutive chunk of pairs.\\n\\nSo this seems like a viable approach. Then, for each group, output the elements of each pair in the order they are stored. For example, group 0\\'s elements would be 1, 16, 2,15.\\n\\nBut when n is even, this should work.\\n\\nTesting this for n=2: the first group is pair0 (1,4), output as 1 4. The second group is pair1 (2,3), output as 2 3. Which matches the sample.\\n\\nAnother test case: let\\'s think for n=4.\\n\\nGroup 0\\'s pairs are (1,16), (2,15). Output would be 1 16 2 15. Sum is 1+16=17, 2+15=17 → total 34. Which is correct.\\n\\nSo this approach seems correct.\\n\\nSo the code can be written as follows:\\n\\nRead n.\\n\\nGenerate all pairs (i, n² -i +1) for i from 1 to (n²)/2.\\n\\nSplit the pairs into n groups, each of size (n/2) pairs.\\n\\nFor each group, print all elements of the pairs in the group. The order of elements can be first element of the first pair, second element of the first pair, first of second pair, second of second pair, etc. So for each pair in the group, output a and b in order. So for group 0\\'s pairs (1,16) and (2,15), output 1 16 2 15.\\n\\nSo code steps:\\n\\nRead n.\\n\\nCompute m = n*n.\\n\\nGenerate pairs.\\n\\nSplit pairs into groups. For each group in 0 to n-1:\\n\\n   start = group * (n/2) pairs.\\n\\n   end = start + (n/2) pairs.\\n\\n   for each pair in start to end-1:\\n\\n       output pair.first and pair.second.\\n\\nSo code:\\n\\n#include <vector>\\nusing namespace std;\\n\\nint main() {\\n    int n;\\n    cin >> n;\\n    int m = n * n;\\n    vector<pair<int, int>> pairs;\\n    for (int i = 1; i <= m/2; ++i) {\\n        pairs.emplace_back(i, m - i +1);\\n    }\\n    int per_group = n / 2;\\n    for (int g = 0; g < n; ++g) {\\n        int start = g * per_group;\\n        int end = start + per_group;\\n        for (int p = start; p < end; ++p) {\\n            cout << pairs[p].first << \" \" << pairs[p].second << \" \";\\n        }\\n        cout << endl;\\n    }\\n    return 0;\\n}\\n\\nWait, but this code will output n lines, each line with n elements. Because per group, per_group is n/2 pairs, each pair contributes 2 elements. So per group, 2*(n/2) =n elements. So yes.\\n\\nBut when the code outputs, each line has 2*per_group elements. For example, per_group is 2 for n=4: 2 pairs → 4 elements. So output line would have 4 elements.\\n\\nBut when the code prints, for each pair in the group, it appends pair.first and pair.second, separated by spaces. Then a newline.\\n\\nBut in the sample input, the output for n=2 is:\\n\\n1 4\\n2 3\\n\\nWhich is exactly what the code would generate. For group 0: first pair (1,4), outputs 1 4. Group1: pair1 (2,3) → 2 3.\\n\\nSo the code works for the sample. What about other cases?\\n\\nAnother example: n=4. The first group has pairs 0 and1 (1,16 and 2,15). Output is 1 16 2 15. Second group pairs 2 and3 (3,14 and4,13). Output 3 14 4 13. And so on.\\n\\nBut each line\\'s sum is (1+16 +2+15) = 34. Which is correct.\\n\\nSo this approach should work.\\n\\nBut wait, the code\\'s output for the first line is \"1 16 2 15 \", but the trailing space. Then the code adds endl. But the problem statement says that each line should have the numbers printed with spaces, but the trailing space may or may not be present. However, in programming competition problems, trailing spaces are generally allowed. So the code as written will print each line with a trailing space, which is not allowed. Oh right! The problem says to print the numbers in the line in any order, but the code\\'s current approach appends a space after each element, leading to trailing space at the end of each line.\\n\\nSo this will result in presentation error. So how to avoid that.\\n\\nFor example, in the sample code, the output is:\\n\\n1 4\\n2 3\\n\\nEach line has two numbers, separated by space, no trailing space.\\n\\nSo the code needs to print each group\\'s elements, separated by spaces, but without a trailing space.\\n\\nSo in the code, for each group, we need to print all elements separated by spaces, but without a trailing space.\\n\\nSo the current code does:\\n\\nfor each pair in group:\\n   cout << first << \" \" << second << \" \";\\n\\nWhich will add two numbers each with a space, but for the group, per_group pairs → 2*per_group elements.\\n\\nFor example, per_group=2, each group has 2 pairs, 4 elements. The code would output \"a b c d \" (with space after d).\\n\\nSo the line ends with a space, which is incorrect.\\n\\nSo the code needs to print the elements in the group in a way that each element is followed by a space except the last one.\\n\\nSo how to do that.\\n\\nOne way is to collect all elements of the group in a vector, then print them joined by spaces.\\n\\nAlternative approach: for each group, collect all the elements first, then output them space-separated.\\n\\nSo for each group:\\n\\nvector<int> elements.\\n\\nfor each pair in the group:\\n   elements.push_back(pair.first);\\n   elements.push_back(pair.second);\\n\\nThen, for i in 0 to elements.size() -1:\\n\\n   if (i !=0) cout << \" \";\\n   cout << elements[i];\\n\\nSo code:\\n\\nfor (int g=0; g <n; g++) {\\n    int start = g*per_group;\\n    int end = start + per_group;\\n    vector<int> els;\\n    for (int p=start; p<end; p++) {\\n        els.push_back(pairs[p].first);\\n        els.push_back(pairs[p].second);\\n    }\\n    for (int i=0; i<els.size(); i++) {\\n        if (i !=0) {\\n            cout << \" \";\\n        }\\n        cout << els[i];\\n    }\\n    cout << endl;\\n}\\n\\nThis way, the elements are printed without trailing space.\\n\\nYes. So this modification is needed.\\n\\nSo the code would generate the lines correctly.\\n\\nSo the final code would look like this:\\n\\nRead n.\\n\\nCompute m =n*n.\\n\\nGenerate all pairs.\\n\\nSplit into groups of per_group = n/2 pairs.\\n\\nFor each group:\\n\\n   collect all elements (first and second of each pair in the group).\\n\\n   print them space-separated, no trailing space.\\n\\nThis should solve the problem.\\n\\nTesting for sample input n=2:\\n\\npairs are (1,4) and (2,3).\\n\\nGroup0: pairs[0], per_group=1. So collect 1 and4. So elements [1,4]. Output as \"1 4\".\\n\\nGroup1: pairs[1]. elements [2,3]. Output \"2 3\".\\n\\nWhich matches the sample.\\n\\nAnother test case: n=4.\\n\\nGroup0: pairs 0 and1 (1,16 and 2,15). elements [1,16,2,15]. output \"1 16 2 15\".\\n\\nWhich is correct.\\n\\nSo the code should work.\\n\\nNow, implement this in C++.\\n\\nThe code:\\n\\n#include <iostream>\\n#include <vector>\\nusing namespace std;\\n\\nint main() {\\n    int n;\\n    cin >> n;\\n    int m = n * n;\\n    vector<pair<int, int>> pairs;\\n    for (int i = 1; i <= m/2; ++i) {\\n        pairs.emplace_back(i, m - i + 1);\\n    }\\n    int per_group = n / 2;\\n    for (int g = 0; g < n; ++g) {\\n        int start = g * per_group;\\n        vector<int> elements;\\n        for (int p = start; p < start + per_group; ++p) {\\n            elements.push_back(pairs[p].first);\\n            elements.push_back(pairs[p].second);\\n        }\\n        for (size_t i = 0; i < elements.size(); ++i) {\\n            if (i != 0) {\\n                cout << \" \";\\n            }\\n            cout << elements[i];\\n        }\\n        cout << endl;\\n    }\\n    return 0;\\n}\\n\\nThis should work.\\n</think>\\n\\n```cpp\\n#include <iostream>\\n#include <vector>\\nusing namespace std;\\n\\nint main() {\\n    int n;\\n    cin >> n;\\n    int m = n * n;\\n    vector<pair<int, int>> pairs;\\n    for (int i = 1; i <= m/2; ++i) {\\n        pairs.emplace_back(i, m - i + 1);\\n    }\\n    int per_group = n / 2;\\n    for (int g = 0; g < n; ++g) {\\n        int start = g * per_group;\\n        vector<int> elements;\\n        for (int p = start; p < start + per_group; ++p) {\\n            elements.push_back(pairs[p].first);\\n            elements.push_back(pairs[p].second);\\n        }\\n        for (size_t i = 0; i < elements.size(); ++i) {\\n            if (i != 0) {\\n                cout << \" \";\\n            }\\n            cout << elements[i];\\n        }\\n        cout << endl;\\n    }\\n    return 0;\\n}\\n```<|im_end|>\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|██████████| 47880/47880 [08:11<00:00, 97.34 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4, # Fixed major bug in latest Unsloth\n",
    "        warmup_steps = 5,\n",
    "        #num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"paged_adamw_8bit\", # Save more memory\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n\\n            You will be given a competitive programming problem. Please reason step by step about the solution, then provide a complete implementation in C++17.\\n\\n            If starter code is provided below, fill in the starter code; \\n            otherwise, create a Solution class and fill it in. Your solution must be a function that takes the input as arguments, and returns the answer.\\n\\n            Put your final solution within a single code block:\\n            ```cpp\\n            <your code here>\\n            ```\\n            Only output the final solution code.\\n            # Problem\\n            \\nYou are given a string `s`. Reorder the string using the following algorithm:\\n\\n1.  Pick the **smallest** character from `s` and **append** it to the result.\\n2.  Pick the **smallest** character from `s` which is greater than the last appended character to the result and **append** it.\\n3.  Repeat step 2 until you cannot pick more characters.\\n4.  Pick the **largest** character from `s` and **append** it to the result.\\n5.  Pick the **largest** character from `s` which is smaller than the last appended character to the result and **append** it.\\n6.  Repeat step 5 until you cannot pick more characters.\\n7.  Repeat the steps from 1 to 6 until you pick all characters from `s`.\\n\\nIn each step, If the smallest or the largest character appears more than once you can choose any occurrence and append it to the result.\\n\\nReturn _the result string after sorting_ `s` _with this algorithm_.\\n\\n**Example 1:**\\n\\n**Input:** s =  \"aaaabbbbcccc \"\\n**Output:**  \"abccbaabccba \"\\n**Explanation:** After steps 1, 2 and 3 of the first iteration, result =  \"abc \"\\nAfter steps 4, 5 and 6 of the first iteration, result =  \"abccba \"\\nFirst iteration is done. Now s =  \"aabbcc \" and we go back to step 1\\nAfter steps 1, 2 and 3 of the second iteration, result =  \"abccbaabc \"\\nAfter steps 4, 5 and 6 of the second iteration, result =  \"abccbaabccba \"\\n\\n**Example 2:**\\n\\n**Input:** s =  \"rat \"\\n**Output:**  \"art \"\\n**Explanation:** The word  \"rat \" becomes  \"art \" after re-ordering it with the mentioned algorithm.\\n\\n**Constraints:**\\n\\n*   `1 <= s.length <= 500`\\n*   `s` consists of only lowercase English letters.<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, I need to solve this problem where I have to reorder a string according to a specific algorithm. Let me read the problem carefully again.\\n\\nThe algorithm works in steps. The first part is picking the smallest character, then the next smallest larger than the last, and so on until you can\\'t pick anymore. Then you pick the largest, then the next largest smaller than the last, and repeat. Then you start again until all characters are used.\\n\\nHmm. So each full cycle is steps 1-6. Let\\'s see the example. For \"aaaabbbbcccc\", the first iteration\\'s steps 1-3 give \"abc\", then steps 4-6 give \"abccba\". Then the remaining characters are \"aabbcc\". Then repeat the process: steps 1-3 again would take the smallest available, which is a, then b, then c, adding \"abc\" again. Then steps 4-6 take the largest (c), then b, then a, adding \"cba\". So overall, combining them gives \"abccbaabccba\".\\n\\nSo the process alternates between building up the smallest possible increasing sequence (step 1-3) and then the largest possible decreasing sequence (steps 4-6), but each time using the remaining characters.\\n\\nSo the approach is to repeatedly collect the smallest possible characters in increasing order, then the largest possible in decreasing order, until all are used.\\n\\nThe key is to track the counts of each character. For each iteration, in the first part, we take the smallest possible available, then next smallest larger than previous, etc. Then in the second part, we take the largest possible, then next smallest.\\n\\nWait, how do we model this?\\n\\nLet me think about the counts. Let\\'s say we have a frequency map or array. For each iteration:\\n\\n1. For steps 1-3 (ascending part), we need to collect characters in order, each next character must be the smallest available that\\'s larger than the last. So for each step, we pick the next possible character.\\n\\nBut how do we do this efficiently? Let\\'s see. For the first part, the first character is the smallest available. Then, for the next character, we look for the smallest available that\\'s larger than the current. We continue until there are no such characters left. Then, for the second part, we pick the largest available, then the next largest that\\'s smaller than the current, etc.\\n\\nSo the process is: in each iteration, we first collect a chain of increasing characters (smallest possible at each step), then a chain of decreasing characters (largest possible at each step).\\n\\nSo perhaps, we can model this by first sorting the characters and building a frequency count, then processing them in the required order.\\n\\nLet\\'s think of the frequency as a sorted list of characters with their counts. For example, if the input is \"aaaabbbbcccc\", the sorted list would be a (4), b (4), c (4). Then, in the first part (steps 1-3), we take one of each starting from the first, then second, etc. Wait, but how?\\n\\nAlternatively, perhaps the way to approach this is to collect all the characters in a sorted multiset, and then alternately build the ascending and descending sequences.\\n\\nBut how to manage the counts.\\n\\nWait, here\\'s an idea. Let\\'s create a frequency array where each element is a pair of (character, count), sorted in order. Then, for the ascending part, we iterate through the characters in order, taking one from each if possible, but only if the character is larger than the last one added. Wait, but how does that work? For example, in the first part, the first character is the smallest available. Then the next must be the next smallest available that\\'s larger. So perhaps, the first part is constructed by starting with the first available character (smallest), then the next available smallest larger than that, and so on. Similarly for the second part.\\n\\nBut how to track which characters are available and their counts. So perhaps for each iteration (each full cycle of steps 1-6), we need to:\\n\\n- For the ascending part:\\n   - Start with the first available character (smallest) with count >0. Decrement count by 1, add to result.\\n   - Then find the next character in sorted order which is larger than the last added and has count >0. Repeat until no such character exists.\\n- Then for the descending part:\\n   - Start with the last available character (largest) with count >0. Decrement count by 1, add to result.\\n   - Then find the next largest character smaller than last added with count >0. Repeat until no such character exists.\\n\\nSo the process alternates between these two steps until all counts are zero.\\n\\nSo the steps for each full iteration are:\\n\\n1. Collect the ascending sequence:\\n   a. Find the smallest character available (the first in the sorted list with count >0).\\n   b. Add it to the result, decrement count.\\n   c. Then, find the next smallest character larger than the last added, add it, decrement count.\\n   d. Repeat until no such character can be found.\\n\\n2. Collect the descending sequence:\\n   a. Find the largest character available (last in the sorted list with count >0).\\n   b. Add it to the result, decrement count.\\n   c. Then, find the next largest character smaller than the last added, add it, decrement count.\\n   d. Repeat until no such character can be found.\\n\\nRepeat these two steps until all characters are used.\\n\\nSo the key is to track the available characters and their counts. Let\\'s model this with a frequency array sorted in order. Then, for each ascending step, we can iterate through the array from left to right, but only taking characters that are larger than the previous.\\n\\nBut how to manage the order and the selection. Let\\'s think with the example:\\n\\nFirst example: sorted as a, b, c, each with count 4.\\n\\nFirst ascending step:\\n\\nTake a (count becomes 3). Next, look for the smallest >a, which is b (count 4, now 3). Then c (count 4, now 3). So the ascending part is a, b, c. Then the descending part: largest available is c (count 3-1=2), then b (3-1=2), then a (3-1=2). So the descending part is c, b, a. So first iteration\\'s total is abccba. Then, the counts are a:2, b:2, c:2.\\n\\nNext iteration, ascending: start with a (count 2-1=1), then b (2-1=1), then c (2-1=1). Then descending: c (1-1=0), b (1-1=0), a (1-1=0). So the next part is abc followed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 47,880 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 68,812,800/14,838,846,464 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.665700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.617200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.638900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.607200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.671800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.590300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.651300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.721100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.591100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.585900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.679700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.604800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.636600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.630300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.480200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.654500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_gpu_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m used_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_reserved() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m used_memory_for_lora \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(used_memory \u001b[38;5;241m-\u001b[39m \u001b[43mstart_gpu_memory\u001b[49m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m used_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(used_memory         \u001b[38;5;241m/\u001b[39mmax_memory\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m lora_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(used_memory_for_lora\u001b[38;5;241m/\u001b[39mmax_memory\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_gpu_memory' is not defined"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I need to solve this problem where I'm given a tree and each node has a value. The goal is to find the longest special path. A special path is a downward path where all node values are distinct except for at most one value that appears twice. Then, return the length of the longest path and the minimum number of nodes in all possible longest paths.\n",
      "\n",
      "Hmm. Let's think about how to approach this. The problem seems a bit complex, but I'll break it down.\n",
      "\n",
      "First, the tree is rooted at 0. So each node has a parent except the root. The edges are given in a way that connects the nodes, but not necessarily in a parent-child order. So I need to build the tree structure, determining the parent of each node.\n",
      "\n",
      "Once the tree is built, for each node, I need to explore all possible paths downward, keeping track of the values. Since the path is downward, each node can only be visited once in a path, so the path is a simple path from a node to one of its descendants.\n",
      "\n",
      "The key is that in the path, all values must be unique except for one value that can appear exactly twice. So, the path can have at most two occurrences of a single value, and all others must be unique.\n",
      "\n",
      "So, for each node, I need to find the longest path starting from it, where the path meets this condition. Then, among all possible paths, find the maximum length and the minimum number of nodes in those maximum-length paths.\n",
      "\n",
      "How do I efficiently "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextStreamer\n\u001b[1;32m     73\u001b[0m text_streamer \u001b[38;5;241m=\u001b[39m TextStreamer(tokenizer, skip_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_streamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                   \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/unsloth/models/llama.py:1579\u001b[0m, in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode(), torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1579\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/peft/peft_model.py:1838\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1837\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1838\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1840\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/unsloth/models/llama.py:1579\u001b[0m, in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode(), torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1579\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3214\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3216\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3217\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3218\u001b[0m     outputs,\n\u001b[1;32m   3219\u001b[0m     model_kwargs,\n\u001b[1;32m   3220\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3221\u001b[0m )\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/unsloth/models/llama.py:1026\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1010\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/unsloth/models/llama.py:962\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    954\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[1;32m    955\u001b[0m X \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(\n\u001b[1;32m    956\u001b[0m     decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm,\n\u001b[1;32m    957\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    960\u001b[0m     variance \u001b[38;5;241m=\u001b[39m variance,\n\u001b[1;32m    961\u001b[0m )\n\u001b[0;32m--> 962\u001b[0m X, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaAttention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    972\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/deepleet/venv/lib/python3.10/site-packages/unsloth/models/llama.py:229\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    227\u001b[0m RH_K[:,:,:,:h] \u001b[38;5;241m=\u001b[39m Kn[:,:,:,h:]\n\u001b[1;32m    228\u001b[0m RH_K[:,:,:,h:] \u001b[38;5;241m=\u001b[39m Kn[:,:,:,:h]\n\u001b[0;32m--> 229\u001b[0m \u001b[43mRH_K\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#torch.neg(RH_K[:,:,:,:h], out = RH_K[:,:,:,:h])\u001b[39;00m\n\u001b[1;32m    230\u001b[0m Kn \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m cos\n\u001b[1;32m    231\u001b[0m Kn\u001b[38;5;241m.\u001b[39maddcmul_(RH_K, sin)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen-2.5\",\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "stmt = R\"\"\"\n",
    "You are given an undirected tree rooted at node 0, with n nodes numbered from 0 to n - 1. This is represented by a 2D array edges of length n - 1, where edges[i] = [ui, vi, lengthi] indicates an edge between nodes ui and vi with length lengthi. You are also given an integer array nums, where nums[i] represents the value at node i.\n",
    "\n",
    "A special path is defined as a downward path from an ancestor node to a descendant node in which all node values are distinct, except for at most one value that may appear twice.\n",
    "\n",
    "Return an array result of size 2, where result[0] is the length of the longest special path, and result[1] is the minimum number of nodes in all possible longest special paths.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: edges = [[0,1,1],[1,2,3],[1,3,1],[2,4,6],[4,7,2],[3,5,2],[3,6,5],[6,8,3]], nums = [1,1,0,3,1,2,1,1,0]\n",
    "\n",
    "Output: [9,3]\n",
    "\n",
    "Explanation:\n",
    "\n",
    "In the image below, nodes are colored by their corresponding values in nums.\n",
    "\n",
    "The longest special paths are 1 -> 2 -> 4 and 1 -> 3 -> 6 -> 8, both having a length of 9. The minimum number of nodes across all longest special paths is 3.\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Input: edges = [[1,0,3],[0,2,4],[0,3,5]], nums = [1,1,0,2]\n",
    "\n",
    "Output: [5,2]\n",
    "\n",
    "Explanation:\n",
    "\n",
    "The longest path is 0 -> 3 consisting of 2 nodes with a length of 5.\n",
    "\n",
    " \n",
    "\n",
    "Constraints:\n",
    "\n",
    "    2 <= n <= 5 * 104\n",
    "    edges.length == n - 1\n",
    "    edges[i].length == 3\n",
    "    0 <= ui, vi < n\n",
    "    1 <= lengthi <= 103\n",
    "    nums.length == n\n",
    "    0 <= nums[i] <= 5 * 104\n",
    "    The input is generated such that edges represents a valid tree.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "template = R\"\"\"\n",
    "class Solution {\n",
    "public:\n",
    "    vector<int> longestSpecialPath(vector<vector<int>>& edges, vector<int>& nums) {\n",
    "        \n",
    "    }\n",
    "};\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": stmt + \"Solve the problem in C++ using this template: \" + template},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 32768,\n",
    "                   use_cache = True, temperature = 0.6, top_p = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub_gguf(\"lordtachanka/DeepSeek-R1-Distill-Qwen-14B-leet\",tokenizer,quantization_method = [\"q8_0\",\"q4_k_m\"],token=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
